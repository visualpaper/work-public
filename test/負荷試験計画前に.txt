【計画前の指針】
[モリタリングすべき内容として]
* スループット
  目標を達成していることを見る。
  ⇒ (API ごとに判断する場合は) 攻撃ツールにて確認
  ※ ELB/EC2 にもメトリクスがあるか、全 API が対象になるため

* レイテンシ
  目標を達成していることを見る。
  ⇒ (API ごとに判断する場合は) 攻撃ツールにて確認
  ※ ELB/EC2 にもメトリクスがあるが、全 API が対象になるため

* CPU 利用率
  正しく負荷がかかっていることを確認する。
  ⇒ CloudWatch で確認 (EC2 - CPUUtilization)
     ※ top コマンドでは、ユーザ/システム別・コア別の利用率も確認可能
        (ユーザ CPU 利用率はアプリケーションそのもの、システムの CPU 利用率はファイルやネットワーク入出力によって利用率が上がる)        

* メモリ利用率
  意図せず高くなっていないことを確認する。
  ※ 使用中のメモリ量が全体のメモリ量を超えると著しくパフォーマンスが落ちる (またはプロセス kill される)
  ⇒ vmstat コマンド or カスタムメトリクスにて CloudWatch 上確認可能
     (全体/使用中/未使用のメモリ量を見る)

[例] 2 秒ごとにリソース利用状況を出力してみる
```
[ec2-user@ip-10-0-0-34 ~]$ vmstat 2
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0 2662824   2088 517656    0    0     3     2   20   15  0  0 100  0  0
 0  0      0 2662692   2088 517656    0    0     0     0  213  295  0  0 100  0  0
 0  0      0 2662840   2088 517656    0    0     0     0  187  302  0  0 100  0  0
 1  0      0 2643464   2088 518440    0    0    58   247 7376 11024 57 11 32  0  0
 0  0      0 2630492   2088 519352    0    0     0     0 7316 11137 49 12 38  0  0
11  0      0 2612160   2088 519960    0    0     0     0 6774 10265 30 10 60  0  0
 1  0      0 2571000   2088 520644    0    0     0     0 6159 9497 31  9 60  0  0
 0  0      0 2558940   2088 521180    0    0     0     0 6475 10807 38 10 52  0  0
 0  0      0 2565356   2088 521460    0    0     0     0 6034 9880 24  8 68  0  0
 0  0      0 2562716   2088 522000    0    0     0     0 6145 9422 20  9 71  0  0
 0  0      0 2555368   2088 522256    0    0     2     0 5500 9107 26  8 65  0  0
24  0      0 2540008   2088 523068    0    0     0   160 5462 8500 27  9 64  0  0
 0  0      0 2538200   2088 523460    0    0     0     0 5692 8997 19  9 72  0  0
 0  0      0 2535240   2088 523768    0    0     0     0 5625 8750 26  9 66  0  0
 0  0      0 2534344   2088 524272    0    0     0  6616 5301 8369 12  8 80  0  0
13  0      0 2531264   2088 524476    0    0     0     0 5575 8939 13 10 77  0  0
11  0      0 2515844   2088 525108    0    0     2     0 5491 8239 12  9 79  0  0
 0  0      0 2480240   2088 525460    0    0     0     0 5545 9110 15 10 75  0  0
```

* ネットワーク転送量
  意図せず高くなっていないことを確認する。
  ※ インスタンスタイプ別に転送量 (xxGbps 制限が記載されている) の目安がある。
  ⇒ NetworkPacketsIn/NetworkPacketsOut にて CloudWatch 上確認可能
     (ELB/EC2 共に確認可能)

* コネクション利用率
  TCS ポートが枯渇していないことを確認する。
  (参考) https://qiita.com/toast-uz/items/9a5c14b8e2b4736e6616
  ⇒ 攻撃ツール上での Failes 結果 (コネクションタイムアウト) で確認可能
  ※ State が TIME_WATE のポートが大量に残っていると TCP/IP 通信ができなくなり、コネクションタイムアウトが発生する。
     (ミドルウェアに接続できなくなったりする)
  ※ netstat コマンドでの TIME_WAIT の状態を監視しておくのも良いと思われる。
  ※ 対象サーバだけでなく、攻撃サーバ上でもポート枯渇問題が起きる可能性があるため、注意が必要

* I/O 利用率
  IO クレジットが枯渇していないことを確認する。
  ⇒ CPUCreditUsage/CPUCreditBalance で確認可能

* I/O Read/Write 量
  意図せず利用率が高くなっていないことを確認する。
  ⇒ NetworkPacketsIn/NetworkPacketsOut で確認可能

* ミドルウェア (DynamoDB 等の利用状況)
  ※ 各々のコンポーネントで確認内容が異なる。
  ⇒ コンポーネント別のメトリクスで確認可能


[プロファイリングについて]
* システムの外部から見えないシステムのボトルネックを洗い出すために利用する
  意図せずリソース消費が発生している場合など、アプリケーションに何らかの問題がある可能性がある場合に用いる。
  ※ プロファイリングツールを有効にした状態では負荷試験に影響が発生するため、
     別途プロファイリング用に試験を実施して、結果を取得するということが必要になる。

  jvisualvm 等でリモート接続にて確認を行うなど。(☆ 良いものが見つからなかった)



[負荷試験計画]
計画～実施を PDCA サイクルを回して実施する。
※ 一度の実施で完了するのではなく、PDCA を回して継続的に改善する。

* 以下の明確にしておく必要がある
  * スケジュール
    期間は既に定められているため割愛

  * 負荷試験の目的
    以前記載した、以下 4 つをベースにどのような目的で負荷試験を行うかを明確にする。
    - ユースケースを想定し、それぞれにおけるシステムの応答性能を推測する
    - 高負荷時におけるシステムの性能改善を行う
    - システムがスケール性を持つことを確認する
    - システムのスケール特性を把握する

  * 前提条件の整理
    目的に沿って、前提条件を明確にする。
    - 試験対象範囲 (品質を保証する範囲を明確にする。例: 1 API の品質を保証する)
    - データ量 (試験時に利用するデータ件数やサイズを決める)
    - 性能維持期間 (x 時間以上継続して性能を維持すること等)
    - 実施方法 (HTTPS を使うか、Stub を使うか等)
    - その他
      例: サービス開始時のシナリオ試験を実施するのであれば、キャッシュ/DB をまっさらにしておく等

  * 目標値
    * rps
      ※ 概算見積もり方法として、最大 RPS に対し、安全係数 (2-3 倍) を掛けた値をベースにすると良い
         (この値をスループット目標値とすることで想定アクセスを問題なく捌けるため)

         - 1日の利用者数 * 1 日あたりの平均アクセス数 = 1日の総アクセス数
         - 1日の総アクセス数 / 1 日の秒数 (86400) = 1日の平均 RPS
         - 1日の平均 RPS * 1 日の平均アクセス数に対する最大ピーク時の倍率 = 最大 RPS
         ※ 5万人の利用者が 20 回平均でアクセスし、平均アクセス数に対する最大ピーク時の倍率は 3 とすると
            50000 * 20 / 86000 * 3 * 3 = 約 100RPS

    * レイテンシ
      ※ 通常の Web システムであれば 50-100ms 以下に抑えることは一つの目安となる
         (トランザクション処理など、サービスの特性によって時間がかかるものはもちろんあるのであくまで目安)

  * 利用するツール
    - 攻撃ツール (locust)
    - モニタリングツール (CloudWatch をベースに、必要に応じて vmstat や top 等を用いる)
    - プロファイリングツール (リモート jvisualvm)

  * 試験実施環境
    * e1 環境上にて実施
      ☆ 前サービスの設定値 (EC2、Dynamo、Apache、Tomcat 等の設定値) があればそちらを参考にしたい。
         別途、(A チームの負荷試験リンク) にある Apache/Tomcat の設定は参考になると思われる。

    * 攻撃サーバは自分で master/slave 構成を整える
      ※ EC2 に対する攻撃であれば、同じ VPC 内に整えて Http アクセス
      ※ ELB に対する攻撃であれば、別ネットワークグループで Https アクセス

  * 負荷試験シナリオ
    リソース消費しやすい、アクセスが集中しやすいものがシナリオ内に含まれていることが望ましい。
    そのようなケース及び、メインシナリオをベースに実施することにより、他シナリオ等は 9 割側問題なくなるため。


[負荷試験実施方法]

* 前提
  * Arpa/Asm などの外部サービスは Stub を利用
    ☆ コネクション接続はしたいので、他 A チームなどで、どのように実施したかを知りたい。

  * その他、ミドルウェア (S3/DynamoDB/Redis) は本物を利用

  * 利用するツールは以下とする
    - 攻撃ツール (locust)
    - モニタリングツール (CloudWatch)
    - プロファイリングツール (datadog ☆ 実際に利用できるかは確認が必要)

Step1. Resource Server に対する負荷試験 (EC2 に対する負荷試験)
  * 負荷試験の目的
    - 高負荷時の性能改善
    - 最少構成での rps/レイテンシを確認する

  * 前提条件の整理
    - サービス開始時の状態を想定した負荷試験
      ※ キャッシュ/DB を空にした状態実施

    - サービス稼働中の状態を想定した負荷試験
      ☆ 本番稼動中のデータを元に、どの程度のキャッシュ/DB の状態にするかを考慮する必要がある

  * 試験実施環境
    - e1 EC2
      ※ EC2 に対する負荷試験のため、同じ VPC 内に整えて Http アクセスできるよう設定が必要

  * 負荷試験シナリオ
    - リソース消費しやすい、アクセスが集中しやすいメインシナリオを 1 つ実施


Step2. スケールアップの試験 (EC2 に対する負荷試験)
  * 負荷試験の目的
    - 高負荷時の性能改善 (前 Step と比較し、極端に rps/レイテンシが下がっていないことを確認する)
    - システムがスケール性を持つことを確認する
    - システムのスケール特性を把握する
   ※ Lonch Planning で提示されている、スケーラビリティ項目の内容を満たしていることを確認する

  * 前提条件の整理
    (Step 1 と同様)

  * 試験実施環境
    (Step 1 と同様)
    ※ スケールアップ対象は EC2/Redis/Dynamo

  * 負荷試験シナリオ
    (Step 1 と同様)


Step3. スケールアウトの試験 (ELB に対する負荷試験)
  * 負荷試験の目的
    - 高負荷時の性能改善 (前 Step と比較し、極端に rps/レイテンシが下がっていないことを確認する)
    - システムがスケール性を持つことを確認する
    - システムのスケール特性を把握する
   ※ Lonch Planning で提示されている、スケーラビリティ項目の内容を満たしていることを確認する

  * 前提条件の整理
    (Step 1 と同様)

  * 試験実施環境
    - e1 ELB
      ※ ECB に対する負荷試験のため、異なるネットワークグループから Https アクセスできるよう設定が必要
    ※ スケールアウト対象は ECB/EC2/Redis

  * 負荷試験シナリオ
    (Step 1 と同様)


Step4. Spine に対する負荷試験 (EC2 に対する負荷試験)
  * 負荷試験の目的
    - 高負荷時の性能改善 (前 Step と比較し、極端に rps/レイテンシが下がっていないことを確認する)
    - 最少構成での rps/レイテンシを確認する

  * 前提条件の整理
    (Step 1 と同様)

  * 試験実施環境
    (Step 1 と同様)

  * 負荷試験シナリオ
    (Step 1 と同様)


Step5. スケールアップの試験 (EC2 に対する負荷試験)
  * 負荷試験の目的
    - 高負荷時の性能改善 (前 Step と比較し、極端に rps/レイテンシが下がっていないことを確認する)
    - システムがスケール性を持つことを確認する
    - システムのスケール特性を把握する
    ※ Lonch Planning で提示されている、スケーラビリティ項目の内容を満たしていることを確認する

  * 前提条件の整理
    (Step 1 と同様)

  * 試験実施環境
    (Step 1 と同様)
    ※ スケールアップ対象は EC2/Redis

  * 負荷試験シナリオ
    (Step 1 と同様)


Step6. スケールアウトの試験 (ELB に対する負荷試験)
  * 負荷試験の目的
    - 高負荷時の性能改善 (前 Step と比較し、極端に rps/レイテンシが下がっていないことを確認する)
    - システムがスケール性を持つことを確認する
    - システムのスケール特性を把握する
    ※ Lonch Planning で提示されている、スケーラビリティ項目の内容を満たしていることを確認する

  * 前提条件の整理
    (Step 1 と同様)

  * 試験実施環境
    - e1 ELB
      ※ ECB に対する負荷試験のため、異なるネットワークグループから Https アクセスできるよう設定が必要
    ※ スケールアウト対象は ECB/EC2/Redis

  * 負荷試験シナリオ
    (Step 1 と同様)


Step7. 各 API に対する負荷試験
  * 負荷試験の目的
    - ユースケースを想定し、それぞれにおけるシステムの応答性能を推測する
    ※ Lonch Planning で提示されている目標値に到達できることを確認する

  * 前提条件の整理
    - 各 API 別に、サービス開始時/稼働中の状態を考慮し、どの程度のキャッシュ/DB の状態にするかを考慮する必要がある

  * 試験実施環境
    - e1 ELB
      ※ ECB に対する負荷試験のため、異なるネットワークグループから Https アクセスできるよう設定が必要

  * 負荷試験シナリオ
    - API 別に 1 つシナリオを実施 (☆ で問題ないと思うが)


Step8. シナリオ試験
  * 負荷試験の目的
    - ユースケースを想定し、それぞれにおけるシステムの応答性能を推測する

  * 前提条件の整理
    - 各シナリオ別に、サービス開始時/稼働中の状態を考慮し、どの程度のキャッシュ/DB の状態にするかを考慮する必要がある

  * 試験実施環境
    - e1 ELB
      ※ ECB に対する負荷試験のため、異なるネットワークグループから Https アクセスできるよう設定が必要

  * 負荷試験シナリオ
    - ☆ 詰める必要がある


Steo9. 耐久試験
  * 負荷試験の目的
    - 長時間、高負荷をかけつづけても、問題がないことを確認する。
    ※ 長時間、高負荷をかけつづけた際の、システムがどのような挙動を行うかを見る目的がある

  * 前提条件の整理
    - サービス稼働中の状態を考慮し、どの程度のキャッシュ/DB の状態にするかを考慮する必要がある

  * 試験実施環境
    - e1 ELB
      ※ ECB に対する負荷試験のため、異なるネットワークグループから Https アクセスできるよう設定が必要

  * 負荷試験シナリオ
    - ☆ 詰める必要がある


【不明点】
* e1 環境での対象サーバ/攻撃サーバ構築方法
  ※ 独自で組み込むにしろ、AWS に負荷試験の申請が必要
     (別 AWS アカウントでの実施になるというお話もあったので、詰める必要がある)

* Stub
  ※ 過去の負荷試験では、外部サービス等の利用を Stub にしていたというお話があったが、
     他サービスでどのように実施しているかを確認する必要がある。

* プロファイリング
  ※ datadog を用いるというお話があるものの、現状どのような状態か不明

* 各種設定値
  ※ 前サービスの値を把握する必要がある


【次に実施する内容】
* 不明点欄にある内容を詰める
* 対象/攻撃サーバの構築方法を明確にする
* 負荷試験シナリオを明確にする
* 可能であれば、不明点を全て解決し、シナリオを一つ流してみる
  (負荷試験実施可能な状態にする)


[実際実験してみた]
* 100 ユーザ 10 秒 RoundUp -> 問題なく 100RPS がでる
* 500 ユーザ 60 秒 RoundUp -> 問題なく 500RPS がでる
* 1000 ユーザ 60 秒 RoundUp -> 500 RPS で頭打ちをくらった。
  ※ 調査した感じ、ELB が怪しいと思われる。あらかじめスケーリング (暖気申請) をする必要があると思われた。
  ※ EC2 側の利用率は低い状態なので、負荷のかけ方が問題かも。

* EC2 に対し 1000 ユーザ 60 秒 RoundUp -> 500 RPS で頭打ちをくらった。
  ※ エラーが多発していた。調査した結果、以下に近いはずだが深くは追っていない。
     http://cloud.flect.co.jp/entry/2018/08/24/130542





[RPS が伸び悩んだ場合に調査したメモ]
* マシン
  コネクション関連
  [/etc/sysctl.conf]
  > net.ipv4.tcp_tw_reuse = 1 (TIME_WAIT 状態の接続を新しい接続で再利用する)
  > net.ipv4.tcp_fin_timeout = 30 (デフォルト 240 秒で timeout するものを 30 秒にする ※ 高負荷時には有用。あまりに小さくすると問題が発生する)
  > sysctl -p (即座に反映)

* Apache
  コネクション関連
  (参考) https://qiita.com/takahashi-kazuki/items/2352aec16d6a1dc40582

* 攻撃サーバ
  マシン性能関連
  > t2.medium 程度に上げる
  ※ multi process 実施 (t2.medium 以降なら multi CPU コアなので、1 台で master/slave 構成を組み立てられる)

↑全て実施することで、1 ELB 1 EC2 マシンで 1000RPS ぐらいは出た。
